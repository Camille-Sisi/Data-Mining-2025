{"title":"Modèles de régression : application sur les offres de Pôle emploi 2020","markdown":{"headingText":"Modèles de régression : application sur les offres de Pôle emploi 2020","headingAttr":{"id":"sec-Modeles-regression","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\nOn cherche maintenant à expliquer un phénomène ou une variable par rapport à d'autres. On va ici s'intéresser au fait qu'une offre de Pôle emploi corresponde à un CDI ou non.\\\nOn va repartir de la base `OffresPE_2020` en réduisant le champ pour améliorer les temps de calcul, par exemple en ne s'intéressant qu'à Paris, puis en retravaillant un peu les variables avant de lancer les modèles de régression.\n\n## La création des bases d'apprentissage et de test\n\nOn crée notre base de travail en ne prenant que les variables qui nous intéressent, dont certaines retravaillées avant (création de variables catégorielles plus pertinentes dans une régression logistique). La fonction `relevel()` permet d'indiquer la modalité de référence que l'on veut dans les régressions futures, ici pour la régression logistique.\n\n```{r warning=FALSE, message=FALSE}\nlibrary(fancycut)\nlibrary(janitor)\nlibrary(tidyverse)\n\nOffresPE_2020 <- readRDS(\"data/OffresPE_2020.Rdata\") \n\nOffresPE_2020$salary_cat <- fancycut(OffresPE_2020$salary_hourly_mean,\n                                    \"Entre 0 et moins que le SMIC (10€)\" = \"(0, 10]\",\n                                    \"Entre le SMIC et le Q1(11,6€)\" = \"(10, 11.6]\", \n                                    \"Entre le Q1 et la moyenne (20,1€)\" = \"(11.6, 20.1]\",\n                                    \"Entre la moyenne et le D9 observée en France(15€)\" = \"(20.1, 28]\",\n                                    \"Entre le D9 et le maximum (40200€)\" = \"(28, 40200)\",\n                                    na.bucket = \"Manquant\")\nOffresPE_2020 %>%  tabyl(salary_cat) %>% adorn_pct_formatting()\n\nOffresPE_reg <- OffresPE_2020 %>% \n  filter(location_departement==\"75\") %>% \n  mutate(mois_publication=months(date_sitePublicationDay, abbreviate = T),\n         mois_publication= factor(mois_publication,\n                                  levels = c(\"janv.\", \"févr.\", \"mars\", \"avr.\", \"mai\", \"juin\", \"juil.\", \n                                             \"août\", \"sept.\", \"oct.\", \"nov.\", \"déc.\")),\n         secteurs=as.factor(case_when(entrepriseSecteur_NAF21 %in% c(\"C\", \"D\", \"E\") ~ \"Industrie\",\n                                      entrepriseSecteur_NAF21 ==\"F\" ~ \"Construction\",\n                                      entrepriseSecteur_NAF21 ==\"G\" ~ \"Commerce\",\n                                      entrepriseSecteur_NAF21 ==\"H\" ~ \"Transports\",\n                                      entrepriseSecteur_NAF21 ==\"I\" ~ \"Hébergement/restauration\",\n                                      entrepriseSecteur_NAF21 ==\"J\" ~ \"Info/com\",\n                                      entrepriseSecteur_NAF21 %in% c(\"K\", \"L\") ~ \"Activités fi et immo\",\n                                      entrepriseSecteur_NAF21 ==\"M\" ~ \"Activités spé, scientifiques et techniques\",\n                                      entrepriseSecteur_NAF21 ==\"N\" ~ \"Activités services administratifs et soutien\",\n                                      entrepriseSecteur_NAF21 ==\"O\" ~ \"Administration publique\",\n                                      entrepriseSecteur_NAF21 ==\"P\" ~ \"Enseignement\",\n                                      entrepriseSecteur_NAF21 ==\"Q\" ~ \"Santé humaine et action sociale\",\n                                      entrepriseSecteur_NAF21 ==\"R\" ~ \"Arts, spectacles et activités récréatives\",\n                                      entrepriseSecteur_NAF21 ==\"S\" ~ \"Autres activités de service\",\n                                      entrepriseSecteur_NAF21 ==\"T\" ~ \"Activités des ménages en tant qu'employeurs\",\n                                      TRUE ~ \"Manquant ou U\")),\n         CDI = as.factor(case_when(contractType == \"CDI\" ~  \"Oui\",\n                                 TRUE ~ \"Non\")),\n         salary_cat=relevel(salary_cat, ref=\"Entre le D9 et le maximum (40200€)\"),\n         secteurs=relevel(secteurs, ref=\"Construction\")) %>% \n  select(mois_publication, salary_cat, CDI, secteurs)\n```\n\nDe manière traditionnelle, dans les modèles de prédiction ou *machine learning*, on n'applique pas le modèle sur l'ensemble de la base de données mais d'abord sur un échantillon dit d'apprentissage puis on le \"teste\" sur l'échantillon restant. On va donc ici suivre ce schéma et diviser notre base de données en deux pour avoir un échantillon d'apprentissage ou d'entraînement, et un autre test.\\\n\\\nOn utilise pour cela la fonction `sample` (mais d'autres fonctions existent) en lui spécifiant la façon de diviser la base avec l'argument `prob=` : ici on choisit de diviser notre base selon un rapport 70% *vs* 30%, autrement dit notre base d'apprentissage comprendra 70% des données de la base initiale, alors que la base de test comprendra les 30% restants. On pourrait procéder à un rapport du type 80% *vs* 20%, ou 75% *vs* 25%, etc.\n\n```{r}\n# On choisit la façon de diviser notre base et on l'applique en créant 2 bases\nsample <- sample(c(TRUE, FALSE), nrow(OffresPE_reg), replace=TRUE, prob=c(0.70,0.3))\nOffresPE_train <- OffresPE_reg[sample, ]\nOffresPE_test  <- OffresPE_reg[!sample, ]\n\n# On regarde quelle est la taille de nos deux bases\ndim(OffresPE_train)\ndim(OffresPE_test)\n\n# On vérifie que les proportions de notre variable d'intérêt sont assez proches\n# entre les deux bases\nlibrary(gt)\nOffresPE_train %>% tabyl(CDI) %>% adorn_pct_formatting() %>% \n  adorn_totals(\"row\") %>% gt()\nOffresPE_test %>% tabyl(CDI) %>% adorn_pct_formatting() %>% \n  adorn_totals(\"row\") %>% gt()\n```\n\nLes deux bases présentent une répartition CDI/pas CDI très proche : dans le 75, environ 78% des offres d'emploi émises sur le site de Pôle emploi sont en CDI.\n\n## Un modèle à visée principale explicative : la régression logistique\n\nLa fonction `glm` du package **`stats`** (à installer avant appel dans la librarie) est principalement utilisée pour modéliser différents types de régression : l'argument `family=binomial(\"logit\")` permet d'utiliser un modèle logit.\n\n```{r}\n# install.packages(\"stats\")\nlibrary(stats)\n```\n\n### Le modèle initial\n\nOn crée le modèle en spécifiant la variable d'intérêt puis les variables explicatives ou l'ensemble des variables présentes dans la base si nous avons déjà procédé à une sélection des variables : c'est le cas ici donc c'est pour cela que l'on indique juste un \".\" après le \"\\~\", sinon on devrait écrire les variables une par une, ou les sctoker dans une liste et appeler la liste.\n\nMême si ce type modèle doit permettre essentiellement d'expliquer un phénomène, ici qu'une offre d'emploi soit en CDI ou non, on peut l'utiliser aussi pour prédire les données. C'est pourquoi nous appliquons d'abord le logit sur la base (réduite) d'apprentissage.\n\n```{r}\nlogit_1 <- glm (CDI ~ ., \n                data=OffresPE_train, \n                family = binomial(\"logit\"))\nsummary(logit_1)\n```\n\nCertaines modalités des variables ne sont pas significatives (voir les étoiles), mais la grande majorité le sont.\n\n<!--On peut ensuite évaluer la significativité globale du modèle, : -->\n\n```{r eval=FALSE, include=FALSE}\nchi2 <- logit_1$null.deviance - logit_1$deviance\nddl <- logit_1$df.null - logit_1$df.residual\npvalue <- pchisq(chi2, ddl, lower.tail = F)\nchi2\nddl\npvalue\n```\n\nOn va donc l'appliquer maintenant à la base test, en créant des indicateurs mesurant le taux de prédiction ou au contraire d'erreur.\n\nLe modèle `predict` permet d'abord d'abord de calculer la probabilité qu'une offre d'emploi soit en CDI pour chaque offre, l'argument `type=\"response\"` permettant d'appliquer le modèle logistique. Il est plus intéressant d'avoir la probabilité d'une variable de type qualitative, \"oui\"/\"non\" comme la variable d'intérêt du modèle, il faut donc procéder à une transformation aboutissant à une nouvelle variable (on considère alors que si la probabilité est strictement supérieure à 0.50 alors cela équivaut à une modalité \"oui\"). Enfin, on crée une matrice de confusion qui est en réalité un tableau croisé entre les valeurs observées et les prédicitions du modèle ; et on calcule un taux d'erreur en rapportant la somme des éléments hors diagonale principale à la somme des observations totales (de la matrice donc).\n\n```{r}\n# Modèle de prédiction pour récupérer les probabilités individuelles d'être en couple\npred.proba <- predict(logit_1, newdata = OffresPE_test, type=\"response\")\n\n# On transforme les probas en variable qualitative\npred.moda <- factor(case_when(pred.proba>0.5 ~ \"oui\", TRUE ~ \"non\"))\n\n# On crée la matrice de confusion\nmatrice_conf <- table(OffresPE_test$CDI, pred.moda)\nmatrice_conf\n\n# On calcule le taux d'erreur\ntx_erreur <- (matrice_conf[2,1]+matrice_conf[1,2])/sum(matrice_conf)\ntx_erreur * 100\n```\n\nOn voit que parmi la modalité observée \"Oui\" de la base de données, le modèle prédit environ 39 000 oui soit 96% de cette modalité, c'est la grande majorité ; la prédiction est moins bonne si on regarde la modalité \"Non\", puisque environ 4 500 observations, soit 39% de cette modalité, se retrouvent bien en \"non\". Le taux d'erreur de 16,3% montre bien néanmoins que le modèle prédit plutôt bien.\\\n\\\n\nUne autre façon de faire est d'ajouter, après les deux premières étapes réécrites ici, la variable de prédiction à la table initiale et de créer une nouvelle variable qui indique si on a bien une correspondance entre les modalités des deux variables : l'initiale et celle prédite. Cela nous donne donc le taux d'erreur calculé au-dessus, on retrouve bien 16,3% de correspondances inexactes.\n\n```{r}\n# Modèle de prédiction pour récupérer les probabilités individuelles d'être en couple\n#pred.proba <- predict(logit_1, newdata = OffresPE_test, type=\"response\")\n\n# On transforme les probas en variable qualitative\n#pred.moda <- factor(case_when(pred.proba>0.5 ~ \"oui\", TRUE ~ \"non\"))\n\n# On ajoute la variable de prédiction dans la table test initiale\nOffresPE_test_bis <- cbind.data.frame(OffresPE_test, var_predict=pred.moda)\n# et on créer une variable indiquant ou non la correspondance entre\n# les modalités des deux variables\nOffresPE_test_bis %>% \n  mutate(predict_OK=as.factor(case_when(CDI==\"Oui\" & var_predict==\"oui\" ~ \"oui\", \n                                        CDI==\"Non\" & var_predict==\"non\" ~ \"oui\",\n                                        TRUE ~ \"non\"))) %>% \n  tabyl(predict_OK) %>% adorn_pct_formatting() %>% adorn_totals(\"row\")\n\n# On supprime la table créée en test\nrm(OffresPE_test_bis)\n```\n\n### L'évaluation du modèle et la recherche éventuelle d'un \"meilleur\" modèle\n\nOn peut améliorer le modèle en recherchant celui qui est le \"meilleur\" en faisant une sélection sur les variables, plus précisément en demandant au modèle de choisir les variables les plus explicatives, car peut-être que certaines ne sont pas nécessaires à l'explication du modèle (dans notre cas, nous avons néanmoins vu que toutes les variables étaient significatives donc a priori utiles dans le modèle).\n\nPour une sélection \"pas à pas\", il faut utiliser le package **`MASS`** et la fonction `stepAIC` car c'est à travers le critère AIC (\"Akaike Information Criterion\",) que le modèle va chercher à être \"meilleur\" : plus il sera faible, meilleur il sera. On va d'abord faire cette sélection de façon \"descendante\" c'est-à-dire en partant du modèle initial \"logit_1\" ici : on part du modèle avec l'ensemble des variables et on en supprime une au fur et à mesure pour voir si le modèle est \"meilleur\".\n\n```{r warning=FALSE, message=FALSE}\n# install.packages(\"MASS)\nlibrary(MASS)\nlogit_backward <- stepAIC(logit_1, \n                          scope=list(lower=\"CDI ~ 1\", \n                          upper=\"CDI ~ mois_publication + secteurs + salary_cat\"),\n                          direction=\"backward\")\nlogit_backward\n```\n\nLa sortie n'affiche que le \"meilleur\" modèle, et c'est donc bien celui qu'on avait mis avec l'ensemble des variables.\n\nPour une sélection des variables de façon \"ascendante\", en partant d'un modèle sans variable puis on ajoute une à une les variables. On utilise la même fonction mais en changeant les paramètres et en créant un modèle \"vide\" avant :\n\n```{r}\nlogit_0 <- glm(CDI ~ 1, data=OffresPE_train, family=binomial(\"logit\"))\nlogit_forward <- stepAIC(logit_0, \n                         scope=list(lower=\"CDI ~ 1\", \n                         upper=\"CDI ~ mois_publication + secteurs + salary_cat\"),\n                         direction=\"forward\")\nlogit_forward\n```\n\nLe taux d'AIC diminue à chaque variable ajoutée donc le meilleur modèle est bien celui avec l'ensemble des variables explicatives mises dans le modèle initial.\n\n```{r eval=FALSE, include=FALSE}\n# Autre façon de tester le modèle avec la fonction drop1:\ndrop1(logit_1, test=\"Chisq\")\n```\n\n### Le modèle final et l'interprétation des résultats\n\nFinalement, dans une visée plus explicative que prédictive, on peut estimer notre modèle sur l'ensemble de la base et étudier plus précisément les résultats avec les *odds-ratios* ou rapports des côtes par exemple pour commenter plus directement les coefficients. Ces *odds-ratios* correspondent à l’exponentiel des coefficients initiaux de la régression. Ils se lisent par rapport à 1 : il est égale à 1 si les deux côtes sont identiques donc s'il n'y a pas de différence de probabilité d'être en couple selon qu'on est une femme ou un homme, il est supérieur à 1 si ici la femme a une probabilité supérieure à celle de l'homme d'être en couple, et il est inférieur à 1 si la femme a une probabilité inférieure à celle de l'homme d'être en couple.\n\n```{r warning=FALSE, message=FALSE}\nlogit_VF <- glm (CDI ~ mois_publication + secteurs + salary_cat,\n                 data=OffresPE_reg, \n                 family = binomial(\"logit\"))\nsummary(logit_VF)\n```\n\n```{r message=FALSE, warning=FALSE}\n# Résumé des résultats sous forme de tableau avec les odds-ratio\n# avec la librairie \"questionr\" d'abord\n#install.packages(questionr)\nlibrary(questionr)\nodds.ratio(logit_VF)\n```\n\n<!-- ![ ](images/Graphique_Odds-ratio.png) -->\n\n```{r warning=FALSE, message=FALSE}\n# puis avec la librarie \"forestmodel\" pour avoir un meilleur rendu\n#install.packages(\"forestmodel\")\nlibrary(forestmodel)\nforest_model(logit_VF, \n             format_options = forest_model_format_options(point_size=2)) +\n  theme(axis.text.x = element_text(size=7, face=\"bold\"))\n```\n\n<!-- ![ ](images/Graphique_Forest_model.png) -->\n\n```{r message=FALSE, warning=FALSE}\n# ou encore avec \"gt_summary\" pour avoir un autre rendu\nlibrary(gtsummary)\ntheme_gtsummary_language(\"fr\", decimal.mark = \",\", big.mark=\" \")\nlogit_VF %>% \n  tbl_regression(exponentiate = TRUE) %>% \n  add_global_p(keep=TRUE) %>% \n  modify_header(label ~ \"**Variable**\") %>% \n  modify_caption(\"**Tableau de résultats. Variables expliquant le fait qu'une offre d'emploi soit en CDI dans le 75**\")\n```\n\nOn privilégiera plutôt les deux derniers types de tableaux : ainsi, on note que la probabilité qu'une offre d'emploi soit en CDI est 1,24 fois plus élevée si l'emploi est dans le secteur de l'hébergement/restauration et 2,67 fois plus élevée dans le secteur de l'information/communication. Concernant le salaire, par rapport à la référence \"Entre le D9 et le maximum (40200€)\", si l'offre d'emploi se situe dans une tranche de salaire plus faible, alors la probabilité que cette offre soit en CDI est plus faible, de 0,05 fois à 0,55 fois, soit une baisse de 45% `((1-0,55)*100)` à 95% `((1-0,05)*100)`. Par rapport au mois de janvier, là aussi, la probabilité qu'une offre d'emploi soit en CDI est plus faible pour tous les autres mois sauf novembre, les odds-ratio étant toujours inférieurs à 1.\n\nOn peut aussi vouloir visualiser ces résultats, on peut pour cela utiliser la librarie **`GGally`** et la fonction `ggcoef_model()`.\n\n```{R message=FALSE}\n# Résumé des résultats sous forme graphqiue\nlibrary(GGally)\nggcoef_model(logit_VF, exponentiate = TRUE) +\n  ggtitle(\"Variables expliquant le fait \\nqu'une offre d'emploi soit en \\nCDI dans le 75\")+\n  theme(plot.title = element_text(size=10))\n```\n\nC'est peut-être le meilleur rendu...\n\n## Un modèle à visée principale prédictive : l'abre de décision\n\nOn va procéder à la même analyse en cherchant, cette fois, à prédire si une offre d'emploi sera en CDI ou non à partir des variables sélectionnées précédemment.\\\nOn repart donc des deux tables créées et on va utiliser un modèle dit d'apprentissage supervisé, l'abre de décision. Sa construction repose sur un partitionnement récursif des observations qui se fait à partir de noeuds coupés, ces coupures pourront répondre à des règles et des conditions à spécifier ou faire varier pour avoir un meilleur modèle.\\\nIci on va utiliser un arbre de classification puisque notre variable est qualitative (binaire).\n\nC'est le package **`rpart`** qui est spécialisé dans les modèles d'arbres de décision, à installer donc d'abord puis à appeler dans la librairie ; le package **`rpart.plot`** permet, lui, d'avoir un arbre plus esthétique et informatif.\n\n```{r warning=FALSE, message=FALSE}\n# install.packages(\"rpart\")\n# install.packages(\"rpart.plot\")\nlibrary(rpart)\nlibrary(rpart.plot)\n```\n\n### Le modèle initial\n\nLa spécification du modèle est assez simple, on précise la variable d'intérêt, les éventuelles variables explicatives ou toutes celles qui sont dans la table avec le `.` (comme précédemment pour le modèle logit), la base de données sur laquelle appliquer le modèle, et dans l'argument `method=` on spécifie le type de modèle, soit \"class\" pour une variable d'intérêt qualitative ou binaire, soit \"anova\" pour une variable d'intérêt quantitative ou continue.\n\nOn va d'abord appliquer le modèle sur notre échantillon d'apprentissage ou d'entraînement :\n\n```{r}\narbre_1 <- rpart(CDI ~ ., \n                 data=OffresPE_train, \n                 method=\"class\")\narbre_1\n```\n\nLe modèle nous donne d'abord les résultats en format texte, ce sont des indications sur les différentes \"noeuds\" puis \"branches\" de l'arbre, etc. : \"node\" pour noeud et son numéro, \"split\" pour la condition de coupure/le critère de décision, \"n\" pour le nombre total d'observations dans un noeud, \"loss\" le nombre d'observations qui n'appartient pas à la modalité prédite, \"yval\" la modalité prédite pour les individus présents à l'étape du noeud, et \"yprob\" la proportion d'observations pour les individus présents à l'étape du noeud qui prend la valeur prédite en seconde position. Le petit astérix \"\\*\" précise que le noeud est une feuille (\"terminal\").\n\nPar exemple, ici le premier noeud indiqué \"root\" représente l'ensemble de l'échantillon (c'est la \"racine\" de l'arbre), soit environ 123 000 observations, et comme la modalité prédite est \"Oui\", il y a 78% d'offres d'emploi qui sont en CDI, contre 22% qui le sont pas soit environ 27 000 observations (celles qu'on perd à cette étape donc). La première variable discriminante est le secteur d'activité : celles qui se situent dans les secteurs \"Activités des ménages en tant qu'employeurs\", ou \"Activités services administratifs et soutien\", ou \"Administration publique\", ou \"Arts, spectacles et activités récréatives\", ou encore \"Enseignement\" forment une première branche et un groupe d'offres qui ne sont pas en CDI, alors que les secteurs de la \"Construction\", ou des \"Activités fi et immo\", ou des \"Activités spé, scientifiques et techniques\", ou des \"Autres activités de service\", ou du \"Commerce\", ou de l'\"Hébergement/restauration\", ou de l'\"Industrie\", ou de l'\"Info/com\", ou \"manquant ou U\", ou de la \"Santé humaine et action sociale\", et enfin des \"Transports\" forment l'autre branche et un groupe d'offres en CDI. Ensuite, pour le premier groupe de secteurs, une autre division se forme selon le niveau de salaire : si l'offre propose un salaire \"Entre 0 et moins que le SMIC (10€)\" ou est manquant un autre groupe va se former qui ne sera pas en CDI, alors que si l'offre propose un salaire au-dessus du SMIC alors l'offre sera en CDI, ce dernier groupe se divisera lui-même encore en deux groupes selon d'autres modalités du salaire.\n\nOn peut regarder quelles sont les variables les plus importantes dans le modèle par ordre :\n\n```{r}\narbre_1$variable.importance\n```\n\nLe secteur d'activité est la variable la plus discriminante, comme on l'avait supposé puisque c'était la première variable qui divisait notre échantillon, ensuite vient le niveau de salaire et enfin le mois de publication de l'offre.\\\n\\\n\nOn va mieux étudier cela avec le résultat visuel.\\\nPour avoir ainsi graphiquement l'arbre, il faut appeler la fonction `rpart.plot()` du même package, l'argument \"extra\" permettant de préciser le type de modèle : \"106\" pour des modèles en classes avec une variable qualitative et binaire, \"104\" pour des modèles en classes mais avec une variable d'intérêt qualitative avec plus de 2 modalités, et \"100\" pour les autres modèles.\n\n```{r message=FALSE, warning=FALSE}\n# On dessine l'arbre\nrpart.plot(arbre_1, extra=106,\n           faclen = 8,  # abrège les modalités de variables\n           cex = 0.75)  # permet de réduire la taille du texte\n\n# ou avec la librarie `rattle`\n#install.packages(\"rattle\")\nlibrary(rattle)\nfancyRpartPlot(arbre_1) \n```\n\nAu sommet de l'arbre on a donc la racine (qui est le 1er noeud), puis il se divise en 2 branches pour aboutir à deux autres noeuds, etc.\\\nOn voit donc que la branche partant sur la gauche, c'est le cas où la variable de secteurs est égale aux modalités \"Activités des ménages en tant qu'employeurs\", ou \"Activités services administratifs et soutien\", ou \"Administration publique\", ou \"Arts, spectacles et activités récréatives\", ou \"Enseignement\" (on voit un \"yes\" qui est encadré ; ça sera le cas à chaque fois même si ce n'est pas de nouveau inscrit, autrement dit la branche partant sur la gauche sera la modalité \"oui\" de la variable).\\\nIl y a chaque fois 3 données indiquées :\n\n-   d'abord, la modalité prédite par le modèle lorsqu'on est dans le groupe considéré, par exemple pour la feuille terminale à droite, donc pour les autres secteurs d'activité que ceux indiqués, la modalité prédite sera le \"oui\" donc une offre en CDI, on pourra vérifier dans les données en récupérant la modalité prédite pour chaque observation, c'est-à-dire pour toutes les offres se situant dans ces secteurs, la modalité prédite est bien \"oui\" ;\n-   ensuite, parmi les offres de ce groupe, 85% sont en CDI, ;\n-   et enfin, ces secteurs représentent 87% de la population (de notre base d'apprentissage).\\\n    Autrement dit, 87% des offres se situent dans ces secteurs avec une probabilité d'être en CDI de 85%.\n\nL'autre branche indique les offres qui prennent les modalités \"Activités des ménages en tant qu'employeurs\", ou \"Activités services administratifs et soutien\", ou \"Administration publique\", ou \"Arts, spectacles et activités récréatives\", ou encore \"Enseignement\" de la variable de secteurs, elles représentent 13% de la base et la probabilité prédite qu'elles soient en CDI sera de 32%.\\\nTout en bas, se trouvent les feuilles de l'arbre, c'est lorsqu'il n'y a plus aucune branche qui part du noeud en question.\n\nAinsi, 5% de la base (d'apprentissage) représentent des offres d'emploi des secteurs \"Activités des ménages en tant qu'employeurs\", ou \"Activités services administratifs et soutien\", ou \"Administration publique\", ou \"Arts, spectacles et activités récréatives\", ou encore \"Enseignement\", avec des niveaux de salaire \"Entre le SMIC et le Q1(11,6€)\" ou \"Entre le Q1 et la moyenne (20,1€)\", qui ont une probabilité de 42% d'être en CDI.\n\n### L'évaluation du modèle\n\nDe la même façon que précédemment, on peut vérifier la bonne (ou non) prédiction du modèle en l'appliquant sur l'échantillon dit test, puis en comparant les proportions prédites avec celles effectivement observées dans la base dans la matrice de confusion et enfin en calculant un taux de concordance ou au contraire un taux d'erreur à partir de cette une matrice de confusion :\n\n```{r}\n# Modèle appliqué sur l'échantillon test\npredict_test <- predict(arbre_1, OffresPE_test, type=\"class\")\n\n# Comparaison des résultats - Matrice de confusion\nmat_confusion <- table(OffresPE_test$CDI, predict_test)\nmat_confusion\n\n# Taux de concordance : rapport entre la somme des éléments \n# de la diagonale principale et la somme des observations \n# totales (soit de la matrice)\ntx_concordance <- sum(diag(mat_confusion) / sum(mat_confusion))\ntx_concordance * 100\n# Taux d'erreur\ntx_erreur <- (mat_confusion[2,1] + mat_confusion[1, 2]) / sum(mat_confusion)\ntx_erreur * 100\n```\n\nOn peut regarder aussi ce que cela donne sur la base d'apprentissage.\n\n```{r}\npredict_train <- predict(arbre_1, OffresPE_train, type=\"class\")\nmat_confusion_1 <- table(OffresPE_train$CDI, predict_train)\nmat_confusion_1\ntx_erreur_1 <- (mat_confusion_1[2,1] + mat_confusion_1[1, 2]) / sum(mat_confusion_1)\ntx_erreur_1 * 100\n```\n\nDans les deux cas, les taux d'erreur sont relativement faible, d'environ 16%. Le modèle ne prédit pas trop mal. On peut noter qu'on a pratiquement le même taux d'erreur que le modèle logit réalisé précédemment...\n\nVérifions si nous pouvons l'améliorer en modifiant les paramètres de construction de l'arbre, c'est-à-dire en jouant sur les conditions de coupure d'un noeud et sur les règles d'arrêt de ces coupures. On l'effectue avec la fonction `rpart.control()` avec les arguments suivants (règles d'arrêt principalement) : `minsplit=` donne le nombre minimum d'observations (individus) présentes à l'étape d'un noeud pour envisager une coupure ; `minbucket=` qui donne le nombre minimum d'observations/individus présentes à l'étape d'un noeud qu'engendrerait la coupure du noeud parent ; `maxdepth` qui donne la profondeur de l'arbre ; et `cp=` qui est un paramètre de complexité (plus il est petit, plus grand est l'arbre de régression).\n\n```{r}\n# Définition des règles de décision\najust_param <- rpart.control(minsplit = 50, minbucket = 50, maxdepth = 10, cp=0)\n\n# Ajustement du modèle en indiquant le paramètre \"control\"\narbre_2 <- rpart(CDI ~ mois_publication + secteurs + salary_cat, \n                 data=OffresPE_train, method=\"class\", \n                 control = ajust_param)\n\n# On étudie de nouveau la matrice de confusion et \n# le taux d'erreur associé au nouveau modèle sur la base test\npredict_test_1 <- predict(arbre_2, OffresPE_test, type=\"class\")\nmat_confusion_ajust <- table(OffresPE_test$CDI, predict_test_1)\nmat_confusion_ajust\ntx_erreur_1 <- (mat_confusion_ajust[2,1] + mat_confusion_ajust[1, 2]) / sum(mat_confusion_ajust) *100\ntx_erreur_1\n```\n\nOn peut l'appliquer de même à l'échantillon d'apprentissage :\n\n```{r}\n# Modèle appliqué sur l'échantillon test\npredict_train <- predict(arbre_2, OffresPE_train, type=\"class\")\n\n# Comparaison des résultats - Matrice de confusion\nmat_confusion_ajust1 <- table(OffresPE_train$CDI, predict_train)\nmat_confusion_ajust1\n\n# Taux d'erreur\ntx_erreur_2 <- (mat_confusion_ajust1[2,1] + mat_confusion_ajust1[1, 2]) / sum(mat_confusion_ajust1)* 100\ntx_erreur_2 \n```\n\nLe taux d'erreur est un peu plus faible, la différence est légère, mais c'est toujours ça de pris !\n\nL'arbre correspondant est le suivant:\n\n```{r}\nrpart.plot(arbre_2, extra=106)\n```\n\nOn voit qu'il n'est absolument pas lisible car plus profond, mais il prédit mieux (mais peut-être trop bien - cf. risque de surapprentissage en *matching learning*).\n\n````{=html}\n<!--Enfin, on peut chercher à minimiser l'erreur de prédiction de l'arbre afin de définir le niveau d'élagage optimal permettant ensuite de simplifier l'arbre.\n``` {R}\n# 2 fonctions liées à l'argument \"cp=\" de notre modèle\nprintcp(arbre_1)\nplotcp(arbre_1)\n\n```\nIci il faut donc indiquer la valeur 0.010 dans l'argument `cp=` pour minimiser l'erreur relative, c'est notre nouvelle règle d'arrêt. On va par conséquent reconstruire l'abre à partir de la fonction `prune()` en indiquant cette valeur optimale pour l'élaguer :  \n```{r}\nmin(arbre_1$cptable[, \"xerror\"]) + (1*arbre_1$cptable[ which.min(arbre_1$cptable[, \"xerror\"]), \"xstd\"])\nopt <- which.min(arbre_1$cptable[, \"xerror\"])\nopt\ncp <- arbre_1$cptable[opt, \"CP\"]\n\narbre_VF <- prune(arbre_1, cp=cp)\nrpart.plot(arbre_VF)\n```\nCela ne change en réalité rien ici ! -->\n````\n\nVous pouvez réitérer l'exercice en introduisant d'autres variables dans l'analyse, en changeant la variable cible, etc.\n\nPour aller plus loin, on utilise maintenant beaucoup en analyse prédictive les forêts d'arbre de décision, qui constituent comme son nom l'indique, un ensemble d'arbres de régression, ce qui permet d'avoir un taux d'erreur global moindre, car la principale critique de l'arbre de décision est son potentiel d'erreur.\n","srcMarkdownNoYaml":""},"formats":{"bookup-html":{"identifier":{"display-name":"HTML","target-format":"bookup-html","base-format":"html","extension-name":"bookup"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"shortcodes":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"filters":["F:\\Enseignements\\Enseignements Univ. Paris Cite 2020-xx\\Data Mining_M2 PISE\\Cours 2023-2025\\Data-Mining-2025\\_extensions\\juba\\bookup\\embed-fonts.lua"],"toc-depth":3,"output-file":"13-Modeles-regression.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.26","embed-fonts":true,"theme":{"light":["_extensions/juba/bookup/bookup.scss"],"dark":["_extensions/juba/bookup/bookup.scss","_extensions/juba/bookup/bookup_dark.scss"]},"revealjs-plugins":[],"toc-title":"Sur cette page"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["bookup-html"]}